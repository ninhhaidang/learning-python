# 01. Pandas Introduction & Series Fundamentals

## üéØ M·ª•c ti√™u h·ªçc t·∫≠p

Sau khi ho√†n th√†nh ch∆∞∆°ng n√†y, b·∫°n s·∫Ω:

- Hi·ªÉu ƒë∆∞·ª£c Pandas l√† g√¨ v√† t·∫°i sao n√≥ quan tr·ªçng trong Data Science
- N·∫Øm v·ªØng c·∫•u tr√∫c d·ªØ li·ªáu Series v√† DataFrame
- Bi·∫øt c√°ch t·∫°o v√† thao t√°c v·ªõi Pandas Series
- Hi·ªÉu relationship gi·ªØa NumPy v√† Pandas
- Th·ª±c hi·ªán basic operations tr√™n Series

## üìö Pandas l√† g√¨?

**Pandas** (Python Data Analysis Library) l√† th∆∞ vi·ªán m·∫°nh m·∫Ω nh·∫•t cho data manipulation v√† analysis trong Python. N√≥ cung c·∫•p:

- **Data structures**: Series (1D) v√† DataFrame (2D)
- **Data I/O tools**: ƒê·ªçc/ghi CSV, Excel, JSON, SQL, HTML...
- **Data cleaning**: Handle missing data, remove duplicates
- **Data transformation**: Grouping, merging, reshaping
- **Analysis tools**: Statistics, time series analysis

### T·∫°i sao Pandas quan tr·ªçng?

1. **User-friendly**: Syntax d·ªÖ hi·ªÉu, t∆∞∆°ng t·ª± SQL/Excel
2. **Performance**: Built tr√™n NumPy, t·ªëi ∆∞u cho big data
3. **Flexibility**: Handle heterogeneous data types
4. **Integration**: K·∫øt h·ª£p t·ªët v·ªõi NumPy, Matplotlib, Scikit-learn
5. **Industry standard**: ƒê∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong Data Science

## üîß C√†i ƒë·∫∑t v√† Import

```python
# C√†i ƒë·∫∑t Pandas
pip install pandas

# Import Pandas
import pandas as pd
import numpy as np

# Ki·ªÉm tra version
print(pd.__version__)
```

## üìä Pandas Series

**Series** l√† c·∫•u tr√∫c d·ªØ li·ªáu 1-dimensional v·ªõi labeled data, t∆∞∆°ng t·ª± nh∆∞ array nh∆∞ng c√≥ index.

### 1. T·∫°o Series

```python
import pandas as pd

# T·ª´ list
series_from_list = pd.Series([1, 2, 3, 4, 5])
print(series_from_list)
# 0    1
# 1    2
# 2    3
# 3    4
# 4    5
# dtype: int64

# T·ª´ list v·ªõi custom index
cities_population = pd.Series(
    [8900000, 1200000, 3500000],
    index=['TP.HCM', 'ƒê√† N·∫µng', 'H√† N·ªôi']
)
print(cities_population)
# TP.HCM     8900000
# ƒê√† N·∫µng    1200000
# H√† N·ªôi     3500000
# dtype: int64

# T·ª´ dictionary
scores_dict = {'To√°n': 8.5, 'L√Ω': 7.0, 'H√≥a': 9.0, 'Sinh': 8.0}
scores_series = pd.Series(scores_dict)
print(scores_series)
# To√°n    8.5
# L√Ω      7.0
# H√≥a     9.0
# Sinh    8.0
# dtype: float64

# T·ª´ NumPy array
import numpy as np
np_array = np.random.randn(5)
series_from_numpy = pd.Series(np_array, index=['A', 'B', 'C', 'D', 'E'])
print(series_from_numpy)
```

### 2. Series Attributes

```python
# T·∫°o series m·∫´u
temperatures = pd.Series([25, 28, 30, 27, 24],
                        index=['Mon', 'Tue', 'Wed', 'Thu', 'Fri'],
                        name='Temperature')

# C√°c thu·ªôc t√≠nh quan tr·ªçng
print(f"Values: {temperatures.values}")      # NumPy array
print(f"Index: {temperatures.index}")        # Index object
print(f"Name: {temperatures.name}")          # Series name
print(f"Shape: {temperatures.shape}")        # (5,)
print(f"Size: {temperatures.size}")          # 5
print(f"Dtype: {temperatures.dtype}")        # int64
print(f"Empty: {temperatures.empty}")        # False

# Statistical info
print(f"Mean: {temperatures.mean()}")        # 26.8
print(f"Max: {temperatures.max()}")          # 30
print(f"Min: {temperatures.min()}")          # 24
print(f"Std: {temperatures.std()}")          # 2.49
```

### 3. Indexing v√† Selection

```python
# Label-based indexing
print(temperatures['Mon'])              # 25
print(temperatures[['Mon', 'Wed']])     # Multiple selection

# Position-based indexing
print(temperatures[0])                  # 25 (first element)
print(temperatures[-1])                 # 24 (last element)
print(temperatures[1:4])                # Slice

# Boolean indexing
hot_days = temperatures[temperatures > 27]
print(hot_days)
# Tue    28
# Wed    30
# dtype: int64

# Conditions
above_average = temperatures[temperatures > temperatures.mean()]
weekend_prep = temperatures[temperatures.index.isin(['Thu', 'Fri'])]
```

### 4. Series Operations

```python
# Arithmetic operations
celsius = pd.Series([0, 20, 30, 40], index=['A', 'B', 'C', 'D'])

# Convert to Fahrenheit
fahrenheit = celsius * 9/5 + 32
print(fahrenheit)
# A     32.0
# B     68.0
# C     86.0
# D    104.0
# dtype: float64

# Mathematical functions
import numpy as np
angles = pd.Series([0, 30, 45, 60, 90], name='degrees')
radians = np.radians(angles)
sine_values = np.sin(radians)

print(sine_values)

# String operations (for string data)
cities = pd.Series(['h√† n·ªôi', 'tp.hcm', 'ƒë√† n·∫µng'])
cities_proper = cities.str.title()
print(cities_proper)
# 0      H√† N·ªôi
# 1      Tp.Hcm
# 2    ƒê√† N·∫µng
# dtype: object
```

### 5. Series Methods

```python
# Sample data
exam_scores = pd.Series([85, 92, 78, 88, 95, 82, 90, 87])

# Descriptive statistics
print(exam_scores.describe())
"""
count     8.000000
mean     87.125000
std       5.815330
min      78.000000
25%      84.250000
50%      87.500000
75%      90.250000
max      95.000000
dtype: float64
"""

# Sorting
sorted_scores = exam_scores.sort_values(ascending=False)
print(sorted_scores)

# Value counts
grades = pd.Series(['A', 'B', 'A', 'C', 'B', 'A', 'B', 'A'])
grade_counts = grades.value_counts()
print(grade_counts)
# A    4
# B    3
# C    1
# dtype: int64

# Unique values
print(f"Unique grades: {grades.unique()}")
print(f"Number of unique: {grades.nunique()}")

# Apply custom functions
def grade_category(score):
    if score >= 90:
        return 'Excellent'
    elif score >= 80:
        return 'Good'
    elif score >= 70:
        return 'Average'
    else:
        return 'Below Average'

categories = exam_scores.apply(grade_category)
print(categories)
```

## üîó Relationship v·ªõi NumPy

```python
# Series ƒë∆∞·ª£c built tr√™n NumPy
import numpy as np
import pandas as pd

# NumPy array
np_array = np.array([1, 2, 3, 4, 5])
print(f"NumPy array: {np_array}")
print(f"Type: {type(np_array)}")

# Convert to Series
series = pd.Series(np_array)
print(f"Pandas Series: {series}")
print(f"Type: {type(series)}")

# Access underlying NumPy array
underlying_array = series.values
print(f"Underlying array: {underlying_array}")
print(f"Are they same? {np.array_equal(np_array, underlying_array)}")

# NumPy operations work on Series
result = np.sqrt(series)
print(f"Square root: {result}")

# Broadcasting still works
series_2d = series.values.reshape(-1, 1) + series.values
print(f"Broadcasting result shape: {series_2d.shape}")
```

## üìä Practical Examples

### Example 1: Vietnam Population Analysis

```python
# Vietnam major cities population (millions)
vietnam_cities = pd.Series({
    'TP. H·ªì Ch√≠ Minh': 9.0,
    'H√† N·ªôi': 8.1,
    'H·∫£i Ph√≤ng': 2.0,
    'ƒê√† N·∫µng': 1.2,
    'C·∫ßn Th∆°': 1.2,
    'Bi√™n H√≤a': 1.1,
    'Hu·∫ø': 0.5,
    'Nha Trang': 0.4,
    'Bu√¥n Ma Thu·ªôt': 0.4,
    'V≈©ng T√†u': 0.3
}, name='Population_Millions')

print("Vietnam Cities Population Analysis")
print("=" * 40)
print(f"Total population: {vietnam_cities.sum():.1f} million")
print(f"Average city size: {vietnam_cities.mean():.1f} million")
print(f"Largest city: {vietnam_cities.idxmax()} ({vietnam_cities.max():.1f}M)")
print(f"Smallest city: {vietnam_cities.idxmin()} ({vietnam_cities.min():.1f}M)")

# Cities with population > 1M
major_cities = vietnam_cities[vietnam_cities >= 1.0]
print(f"\\nMajor cities (‚â•1M): {len(major_cities)}")
print(major_cities)

# Population percentage
total_pop = vietnam_cities.sum()
percentages = (vietnam_cities / total_pop * 100).round(1)
print("\\nPopulation Distribution:")
for city, pct in percentages.items():
    print(f"{city}: {pct}%")
```

### Example 2: Monthly Sales Analysis

```python
# Monthly sales data (in millions VND)
monthly_sales = pd.Series({
    'Jan': 45.2, 'Feb': 52.1, 'Mar': 48.7, 'Apr': 55.3,
    'May': 61.8, 'Jun': 58.9, 'Jul': 67.2, 'Aug': 69.1,
    'Sep': 63.5, 'Oct': 71.3, 'Nov': 78.9, 'Dec': 82.4
}, name='Sales_Millions_VND')

print("Monthly Sales Analysis")
print("=" * 30)

# Basic statistics
print(f"Total annual sales: {monthly_sales.sum():.1f}M VND")
print(f"Average monthly sales: {monthly_sales.mean():.1f}M VND")
print(f"Best month: {monthly_sales.idxmax()} ({monthly_sales.max():.1f}M)")
print(f"Worst month: {monthly_sales.idxmin()} ({monthly_sales.min():.1f}M)")

# Growth analysis
print("\\nQuarterly Performance:")
q1 = monthly_sales[['Jan', 'Feb', 'Mar']].sum()
q2 = monthly_sales[['Apr', 'May', 'Jun']].sum()
q3 = monthly_sales[['Jul', 'Aug', 'Sep']].sum()
q4 = monthly_sales[['Oct', 'Nov', 'Dec']].sum()

quarterly_sales = pd.Series([q1, q2, q3, q4],
                           index=['Q1', 'Q2', 'Q3', 'Q4'],
                           name='Quarterly_Sales')
print(quarterly_sales)

# Month-over-month growth
mom_growth = monthly_sales.pct_change() * 100
print("\\nMonth-over-Month Growth (%):")
print(mom_growth.dropna().round(1))
```

## üîç Missing Data trong Series

```python
# Series with missing data
incomplete_data = pd.Series([100, None, 150, np.nan, 200, 175],
                           index=['A', 'B', 'C', 'D', 'E', 'F'])

print("Original data:")
print(incomplete_data)

# Check for missing data
print(f"\\nHas missing data? {incomplete_data.isnull().any()}")
print(f"Number of missing values: {incomplete_data.isnull().sum()}")
print(f"Number of valid values: {incomplete_data.count()}")

# Handle missing data
print("\\nFilled with mean:")
filled_mean = incomplete_data.fillna(incomplete_data.mean())
print(filled_mean)

print("\\nDrop missing values:")
dropped = incomplete_data.dropna()
print(dropped)

print("\\nForward fill:")
forward_filled = incomplete_data.fillna(method='ffill')
print(forward_filled)
```

## üí° Best Practices

### 1. Naming Convention

```python
# Good: descriptive names
customer_ages = pd.Series([25, 30, 35, 40], name='customer_age')
monthly_revenue = pd.Series(data, name='revenue_millions_vnd')

# Avoid: unclear names
s1 = pd.Series([1, 2, 3])
data = pd.Series(some_values)
```

### 2. Index Management

```python
# Use meaningful indices
temperatures = pd.Series([25, 28, 30], index=['Monday', 'Tuesday', 'Wednesday'])

# For time series, use datetime index
dates = pd.date_range('2024-01-01', periods=3)
time_series = pd.Series([100, 110, 105], index=dates)
```

### 3. Data Validation

```python
# Always check data after creation
print(f"Data shape: {series.shape}")
print(f"Data type: {series.dtype}")
print(f"Missing values: {series.isnull().sum()}")
print(f"Memory usage: {series.memory_usage()} bytes")
```

## üéØ Exercises

### Exercise 1: Basic Series Operations

T·∫°o m·ªôt Series ch·ª©a ƒëi·ªÉm s·ªë c·ªßa 10 h·ªçc sinh v√† th·ª±c hi·ªán:

1. T√≠nh ƒëi·ªÉm trung b√¨nh
2. T√¨m h·ªçc sinh c√≥ ƒëi·ªÉm cao nh·∫•t/th·∫•p nh·∫•t
3. ƒê·∫øm s·ªë h·ªçc sinh ƒë·∫°t ƒëi·ªÉm ‚â• 8.0
4. T·∫°o Series m·ªõi v·ªõi ƒëi·ªÉm ƒë∆∞·ª£c chu·∫©n h√≥a (0-10 scale)

### Exercise 2: Real-world Application

S·ª≠ d·ª•ng d·ªØ li·ªáu gi√° Bitcoin h√†ng ng√†y v√†:

1. T·∫°o Series v·ªõi datetime index
2. T√≠nh volatility (ƒë·ªô bi·∫øn ƒë·ªông)
3. T√¨m ng√†y c√≥ gi√° cao nh·∫•t/th·∫•p nh·∫•t
4. T√≠nh moving average 7 ng√†y

### Exercise 3: Data Cleaning

Cho Series v·ªõi missing data v√† outliers:

1. Ph√°t hi·ªán v√† ƒë·∫øm missing values
2. Fill missing data b·∫±ng c√°c methods kh√°c nhau
3. Detect outliers s·ª≠ d·ª•ng IQR method
4. So s√°nh k·∫øt qu·∫£ c·ªßa c√°c cleaning methods

---

## üìñ T√†i li·ªáu tham kh·∫£o

- [Pandas Official Documentation](https://pandas.pydata.org/docs/)
- [10 Minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)
- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)

**Ti·∫øp theo: DataFrame Fundamentals** üìä
