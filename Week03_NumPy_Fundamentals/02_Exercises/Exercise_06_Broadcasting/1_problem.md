# Exercise 06: Broadcasting Operations

## üéØ M·ª•c ti√™u

- Hi·ªÉu v√† √°p d·ª•ng broadcasting rules trong NumPy
- Th·ª±c h√†nh vectorization ƒë·ªÉ t·ªëi ∆∞u h√≥a performance
- S·ª≠ d·ª•ng broadcasting cho c√°c ph√©p to√°n ma tr·∫≠n
- So s√°nh hi·ªáu su·∫•t gi·ªØa loop v√† vectorized operations

## üìã ƒê·ªÅ b√†i: Broadcasting v√† Vectorization

√Åp d·ª•ng broadcasting ƒë·ªÉ th·ª±c hi·ªán c√°c ph√©p to√°n hi·ªáu qu·∫£ tr√™n arrays c√≥ shape kh√°c nhau.

### Y√™u c·∫ßu:

1. **T·∫°o data arrays** v·ªõi c√°c shape kh√°c nhau
2. **√Åp d·ª•ng broadcasting** ƒë·ªÉ th·ª±c hi·ªán ph√©p to√°n element-wise
3. **Normalize data** b·∫±ng broadcasting (subtract mean, divide by std)
4. **Distance matrix** t√≠nh kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm
5. **Performance comparison** gi·ªØa loop v√† vectorized operations

### Input m·∫´u:

```python
import numpy as np
np.random.seed(42)
# Arrays with different shapes for broadcasting
matrix_2d = np.random.randint(1, 10, (4, 5))
vector_1d = np.random.randint(1, 5, 5)
scalar = 2
```

### Expected Output:

```
=== BROADCASTING & VECTORIZATION ===

Original 2D Matrix (4x5):
[[7 4 6 9 2]
 [6 7 4 4 7]
 [9 8 1 5 3]
 [8 1 5 9 8]]

1D Vector (5,):
[4 1 3 2 1]

Scalar: 2

üî¢ BROADCASTING OPERATIONS:

1. Matrix + Vector (4x5 + 5):
[[11  5  9 11  3]
 [10  8  7  6  8]
 [13  9  4  7  4]
 [12  2  8 11  9]]

2. Matrix * Scalar (4x5 * scalar):
[[14  8 12 18  4]
 [12 14  8  8 14]
 [18 16  2 10  6]
 [16  2 10 18 16]]

üìä NORMALIZATION (Z-score):
Original mean: 5.4, std: 2.8
Normalized matrix:
[[ 0.57 -0.50  0.21  1.29 -1.21]
 [ 0.21  0.57 -0.50 -0.50  0.57]
 [ 1.29  0.93 -1.57 -0.14 -1.07]
 [ 0.93 -1.57 -0.14  1.29  0.93]]

üéØ DISTANCE MATRIX:
Points shape: (3, 2)
Distance matrix (3x3):
[[ 0.    2.83  4.47]
 [ 2.83  0.    3.16]
 [ 4.47  3.16  0.  ]]

‚ö° PERFORMANCE COMPARISON:
Loop method: 0.0045 seconds
Vectorized method: 0.0003 seconds
Speedup: 15.0x faster
```

## üí° H∆∞·ªõng d·∫´n

### Broadcasting Rules:

1. Arrays are aligned from the trailing dimension
2. Dimensions of size 1 can be broadcast
3. Missing dimensions are assumed to be size 1

### C√°c k·ªπ thu·∫≠t c·∫ßn s·ª≠ d·ª•ng:

- `np.newaxis` ho·∫∑c `[:, np.newaxis]` ƒë·ªÉ th√™m dimension
- `np.subtract()`, `np.divide()` v·ªõi broadcasting
- `np.linalg.norm()` cho distance calculation
- `time.time()` ƒë·ªÉ ƒëo performance

### G·ª£i √Ω th·ª±c hi·ªán:

1. Test broadcasting rules v·ªõi arrays shape kh√°c nhau
2. S·ª≠ d·ª•ng `(data - mean) / std` pattern cho normalization
3. D√πng broadcasting ƒë·ªÉ t√≠nh distance matrix hi·ªáu qu·∫£
4. So s√°nh loop vs vectorized b·∫±ng timing

## ‚úÖ Ti√™u ch√≠ ƒë√°nh gi√°

- [ ] Hi·ªÉu v√† √°p d·ª•ng ƒë√∫ng broadcasting rules
- [ ] Th·ª±c hi·ªán normalization b·∫±ng broadcasting
- [ ] T√≠nh distance matrix hi·ªáu qu·∫£
- [ ] So s√°nh performance loop vs vectorized
- [ ] Code clean, c√≥ comment gi·∫£i th√≠ch broadcasting logic
- [ ] Output format r√µ r√†ng, d·ªÖ hi·ªÉu
